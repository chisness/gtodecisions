---
title: "#2: Game Theory"
sidebar: course
format:
  html:
    math: true
---
## 2/3 Game

We played the 2/3 game twice. The goal is to select the number that is 2/3 of the average. We talked a bit about the theory. 

1. It's impossible for anything over 66.67 to win (these are dominated, i.e. always worse) because the maximum is if everyone picks 100 and 2/3 of this is 66.67. 
2. Once you eliminate everything over 66.67, then the maximum anyone should pick is $2/3 * 66.67 = 44.44$. Second level domination: Superior strategy if the opponent doesn't play the first level dominated strategy. 
3. We can keep going by this logic and we'd end up with everyone choosing 0. 
4. But in the real world, this doesn't work! 
5. We can try to model the real world, for example by assuming a uniform random such that the average is 50 and then could choose 2/3, which is 33.33. 
6. The next level to that assumption is that the first level people will choose 33.33, so we should go to the second level and take 2/3 of that, which is 22.22. 
7. What level are people on? What other assumptions could we make?

## Rock Paper Scissors
RPS is a zero-sum game and the payouts are symmetrical as follows: 

| Player 1/2 | Rock    | Paper   | Scissors |
|--------|---------|---------|----------|
| Rock   | (0, 0)  | (-1, 1) | (1, -1)  |
| Paper  | (1, -1) | (0, 0)  | (-1, 1)  |
|Scissors| (-1, 1) | (1, -1) | (0, 0)   |

The Nash Equilibrium strategy is to play each action $r = p = s = 1/3$ of the time. Under Nash equilibrium, no player can gain by unilaterally deviating from their strategy.

A *pure* strategy would mean always playing one action, but a *mixed* strategy is mixing over your possible actions, which is what we see here. 

:::{.callout-tip collapse="true" appearance="minimal"}
## Nash Equilibrium Strategy for RPS
If Player 1 plays Rock with probability $r$, Paper with probability $p$, and Scissors with probability $s$, we have the following expected value equations for Player 2: 

$\mathbb{E}(\text{R}) = -1p + 1s$

$\mathbb{E}(\text{P}) = 1r - 1s$

$\mathbb{E}(\text{S}) = -1r + 1p$

Since no action dominates, we know that the EV of every strategic action should be equal  (since if a certain strategy was best, we'd want to always play that strategy). 

To solve for $r$, $p$, and $s$, we can start by setting these EVs equal: 

$\mathbb{E}(\text{R}) = \mathbb{E}(\text{P})$

$-1p + 1s = 1r - 1s$

$2s = p + r$

Then setting these equal: 

$\mathbb{E}(\text{R}) = \mathbb{E}(\text{S})$

$-1p + 1s = -1r + 1p$

$s + r = 2p$

And finally setting these equal: 

$\mathbb{E}(\text{P}) = \mathbb{E}(\text{S})$

$1r - 1s = -1r + 1p$

$2r = s + p$

Now we have these equations:  

$$
\begin{cases}
2s = p + r \\
s + r = 2p \\
2r = s + p
\end{cases}
$$

We can rewrite the 1st: 

$r = 2s - p$

And combine with the 2nd: 

$s + (2s - p) = 2p$

$3s = 3p$

Resulting in: 

$s = p$

Now we can go back to the 2nd equation: 

$s + r = 2p$

And insert $s$ = $p$: 

$s + r = 2s$

And arrive at: 

$r = s$

We now see that all are equal: 

$s = p = r$

We also know that they must all sum to $1$: 

$r + p + s = 1$

Since they're all equal and sum to $1$, we can substitute $p$ and $s$ with $r$: 

$3r = 1$

$r = 1/3$

So all actions are taken with probability $1/3$: 

$r = p = s = 1/3 \quad \blacksquare$
:::

Playing this strategy means that whatever your opponent does, you will breakeven! For example, think about an opponent that always plays Rock. 

$$
\begin{equation}
\begin{split}
\mathbb{E}(\text{Equilibrium vs. Rock}) &= r*0 + p*1 + s*-1 \\
&= 1/3*0 + 1/3*1 + 1/3*-1 \\
&= 0
\end{split}
\end{equation}
$$

### Nash vs. Exploitative
Although we can play the equilibrium strategy and never lose, we also can't win! If we have a predictable opponent, we're better off in expectation to try to beat them exploitatively. In practice, you could spend some time trying to figure out what they're doing and revert to equilibrium if you're losing. 

### Opponent Modeling
Suppose you knew your opponent played the following, what are the optimal strategies?

1. 60% rock, 0% paper, 40% scissors

Always rock: $0.6*0 + 0*-1 + 0.4*1 = 0.4$

Always paper: $0.6*1 + 0*0 + 0.4*-1 = 0.2$

Always scissors: $0.6*-1 + 0*1 + 0.4*0 = -0.6$

Rock is best! 

This is a tricky one because paper beats the most common opponent move, but is actually worse than rock! 

Note that we only would use a mixed strategy if the EVs were the same for multiple pure strategies. 

2. 20% rock, 20% paper, 60% scissors

Always rock: $0.2*0 + 0.2*-1 + 0.6*1 = 0.4$

Always paper: $0.2*1 + 0.2*0 + 0.6*-1 = -0.4$

Always scissors: $0.2*-1 + 0.2*1 + 0.6*0 = 0$

Rock is best again! 

Note that we assume that the opponent plays fixed strategies. If they were able to update, then we'd probably want to be more subtle about our exploitation. 

### Data: Talk Paper Scissors
[eieio games](https://eieio.games/nonsense/game-13-talk-paper-scissors/) made a Rock Paper Scissors over voice game in which players call a phone number and get matched up with another player for a 3 game RPS match. 

They published their 40,000 round data on X: 

![](tps.png)
**Overall: R 37.2%, P 35.4%, S 27.4%**

![](tpsr1.png)
**Round 1: R 39.7%, P 37.6%, S 22.7%**

![](tpsr2.png)
**Round 2: R 34.0%, 33.4%, 32.6%**

![](tpsr3.png)
**Round 3: R 37.2%, 34.7%, 28.1%**

:::{.callout-note  appearance="minimal"}
## Expected Value Against TPS Player
What is the best strategy per round against the average TPS player? What is your expected value per round and overall?
:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
The best strategy is to always play Paper. 

$\mathbb{E}(\text{Round 1}) = 0.397*1 + 0.376*0 + 0.227*-1 = 0.17$

$\mathbb{E}(\text{Round 2}) = 0.34*1 + 0.334*0 + 0.326*-1 = 0.014$

$\mathbb{E}(\text{Round 3}) = 0.372*1 + 0.347*0 + 0.281*-1 = 0.091$

$\mathbb{E}(\text{Overall}) = 0.17 + 0.014 + 0.091 = 0.275$

:::

## Soccer Kicker
Consider the **Soccer Penalty Kick** game where a Kicker is trying to score a goal and the Goalie is trying to block it. 

| Kicker/Goalie | Lean Left | Lean Right | 
|------------|-----------|--------|
| Kick Left  | 0, 0  | +2, -2 |
| Kick Right | +1, -1 | 0, 0|

The game setup is zero-sum. If Kicker and Goalie both go in one direction, then it’s assumed that the goal will miss and both get $0$ payoffs. If the Kicker plays Kick Right when the Goalie plays Lean Left, then the Kicker is favored and gets a payoff of $+1$. If the Kicker plays Kick Left when the Goalie plays Lean Right, then the kicker is even more favored, because it’s easier to kick left than right, and gets $+2$.

:::{.callout-note  appearance="minimal"}
## Nash Equilibrium Exercise

Which of these, if any, is a Nash equilibrium? You can check by seeing if either player would benefit by changing their action. 

| Kicker | Goalie | Equilibrium or Change? | 
|------------|-----------|--------|
| Left  | Left  |  |
| Left | Right | |
| Right | Left | |
| Right | Right | |

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution

There are no pure Nash equilibrium solutions because when the actions match, the Kicker will always want to change, and when they don’t match, the Goalie will always want to change. 

| Kicker | Goalie | Equilibrium or Change? | 
|------------|-----------|--------|
| Left  | Left  | Kicker changes to right  |
| Left | Right | Goalie changes to left |
| Right | Left | Goalie changes to right |
| Right | Right | Kicker changes to left |
:::


:::{.callout-note  appearance="minimal"}
## Expected Value Exercise
Assume that they both play Left 50% and Right 50% -- what is the expected value of the game? 

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution

| Kicker/Goalie | Lean Left (0.5) | Lean Right (0.5) | 
|------------|-----------|--------|
| Kick Left (0.5) | 0, 0  | +2, -2 |
| Kick Right (0.5) | +1, -1 | 0, 0|

We apply these probabilities to each of the 4 outcomes: 

| Kicker/Goalie | Lean Left (0.5) | Lean Right (0.5) | 
|------------|-----------|--------|
| Kick Left (0.5) | 0, 0 (0.25) | +2, -2 (0.25) |
| Kick Right (0.5) | +1, -1 (0.25) | 0, 0 (0.25) |

Now for the Kicker, we have $\mathbb{E} = 0.25*0 + 0.25*2 + 0.25*1 + 0.25*0 = 0.75$. 

Since it's zero-sum, we have $\mathbb{E} = -0.75$ for the Goalie.

Note that, for example, the Kicker playing 50% Left and 50% Right could be interpreted as a single player having these probabilities or a field of players averaging to these probabilities. So out of 100 players, this could mean: 

- 100 players playing 50% Left and 50% Right
- 50 players playing 100% Left and 50 players playing 100% Right
- 50 players playing 75% Left/25% Right and 50 players playing 25% Left/75% right

:::

When the Goalie plays left with probability $p$ and right with probability $1-p$, we can find the expected value of the Kicker actions.

| Kicker/Goalie | Lean Left (p) | Lean Right (1-p) | 
|------------|-----------|--------|
| Kick Left | 0, 0  | +2, -2 |
| Kick Right | +1, -1 | 0, 0|

$\mathbb{E}(\text{Kick Left}) = 0*p + 2*(1-p) = 2 - 2*p$

$\mathbb{E}(\text{Kick Right}) = 1*p + 0*(1-p) = 1*p$

The Kicker is going to play the best response to the Goalie’s strategy. The Goalie wants to make the Kicker **indifferent** to Kick Left and Kick Right because if the Kicker was not going to be indifferent, then he would prefer one of the actions, meaning that action would be superior to the other. Therefore the Kicker will play a mixed strategy in response that will result in a Nash equilibrium where neither player benefits from unilaterally changing strategies. (Note that indifferent does not mean 50% each, but means the expected value is the same for each.)

![](kickergoalieplot.png)

By setting the values equal, we get $2 - 2*p = 1*p \Rightarrow p = \frac{2}{3}$ as shown in the plot. This means that $1-p = 1 - \frac{2}{3} = \frac{1}{3}$. Therefore the Goalie should play Lean Left $\frac{2}{3}$ and Lean Right $\frac{1}{3}$. The value for the Kicker is $\frac{2}{3}$, or $(0.67)$, for both actions, regardless of the Kicker's mixing strategy. 

Note that the Kicker is worse off now ($0.67$ now compared to $0.75$) than when both players played 50% each action. Why?

If the Kicker plays Left with probability $q$ and Right with probability $1-q$, then the Goalie’s values are: 

$\mathbb{E}(\text{Lean Left}) = 0*q - 1*(1-q) = -1 + q$

$\mathbb{E}(\text{Lean Right}) = -2*q + 0 = -2*q$

Setting equal, 

$$
\begin{equation}
\begin{split}
-1 + q &= -2*q \\
-1 &= -3*q  \\
\frac{1}{3} &= q
\end{split}
\end{equation}
$$

Therefore the Kicker should play Left $\frac{1}{3}$ and Right $\frac{2}{3}$, giving a value of $-\frac{2}{3}$ to the Goalie. 

We can see this from the game table: 

| Kicker/Goalie | Lean Left ($\frac{2}{3}$) | Lean Right ($\frac{1}{3}$) | 
|------------|-----------|--------|
| Kick Left ($\frac{1}{3}$) | 0, 0 ($\frac{2}{9}$) | +2, -2 ($\frac{1}{9}$) |
| Kick Right ($\frac{2}{3}$) | +1, -1 ($\frac{4}{9}$) | 0, 0 ($\frac{2}{9}$)|

Therefore the expected payoffs in this game are $\frac{2}{9}*0 + \frac{1}{9}*2 + \frac{4}{9}*1 + \frac{2}{9}*0 = \frac{6}{9} = 0.67$ for the Kicker and $-0.67$ for the Goalie. 

In an equilibrium, no player should be able to unilaterally improve by changing their strategy. What if the Kicker switches to always Kick Left?

| Kicker/Goalie | Lean Left ($\frac{2}{3}$) | Lean Right ($\frac{1}{3}$) | 
|------------|-----------|--------|
| Kick Left ($1$) | 0, 0 ($\frac{2}{3}$) | +2, -2 ($\frac{1}{3}$) |
| Kick Right ($0$) | +1, -1 ($0$) | 0, 0 ($0$)|

Now the Kicker's payoff is still $\frac{1}{3}*2 = 0.67$. 

When a player makes their opponent indifferent, this means that any action the opponent takes (within the set of equilibrium actions) will result in the same payoff! 

So if you know your opponent is playing the equilibrium strategy, then you can actually do whatever you want with no penalty with the mixing actions. Sort of. 

The risk is that the opponent can now deviate from equilibrium and take advantage of your new strategy. For example, if the Goalie caught on and moved to always Lean Left, then expected value is reduced to $0$ for both players. 

To summarize, you can only be penalized for not playing the equilibrium mixing strategy if your opponent plays a non-equilibrium strategy that exploits your strategy. 

:::{.callout-note  appearance="minimal"}
## Indifference
Why do players make their opponent indifferent?
:::

## Make Your Own
We spent some time thinking of games in groups to try to stump the opposing team. 

### Odds vs. Evens
A game was presented where each player has to simultaneously put out a number 1 or 2 with their fingers. The Odds player wins the sum if it's odd and the Evens player wins the sum if it's even. Would you rather be the Evens or Odds player? 

![](evensodds.jpg)

![](evensodds2.png)

It turns out that the Odds player has a small advantage and wins 1/12 in expectation at equilibrium. 

## Indifference in Poker
We didn't get to this in the class. It's a [Kuhn Poker](https://en.wikipedia.org/wiki/Kuhn_poker) example (see link). It's the simplest strategic poker game that uses a 3 card deck of cards Q/K/A. Each player starts with 2 chips, antes 1 of them, and then has 1 left for betting. 

We can apply the indifference principle in computing equilibrium strategies in poker. When you make your opponent indifferent, then you don’t give them any best play. 

Let’s look at one particular situation in Kuhn Poker and work it out by hand. Suppose that you are Player 2 with card Q after a Check from Player 1. (We could equivalently structure this as a 
river situation in Hold'em where Player 2 has a bluff or a very strong hand and Player 1 has a mid-strength hand.)

![](kuhnindiff.png)

:::{.callout-note  appearance="minimal"}
## Expected Value Exercise
What indifference is Player 2 trying to induce? Compute it.

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
Making P1 indifferent between calling and folding with a K 

We can work out Player 2's betting strategy by calculating the indifference. Let $b$ be the probability that P2 bets with a Q after P1 checks. 

\begin{equation}
\begin{split}
\mathbb{E}(\text{P1 Check K then Fold to Bet}) &= 0 \\
\\

\mathbb{E}(\text{P1 Check K then Call Bet}) &= -1*\Pr(\text{P2 has A and Bets}) + 3*\Pr(\text{P2 has Q and Bets}) \\
  &= -1*\frac{1}{2} + 3*\frac{1}{2}*b \\
  &= -0.5 + 1.5*b
\end{split}
\end{equation}

Setting these equal: 

$0 = -0.5 + 1.5*b$ 

$b = \frac{1}{3}$

Therefore in equilibrium, P2 should bet $\frac{1}{3}$ with Q after P1 checks.  
:::

:::{.callout-note  appearance="minimal"}
## Equilibrium Mixed Strategy Change Exercise
If P2 bet $\frac{2}{3}$ instead of $\frac{1}{3}$ with Q after P1 checks and P1 is playing an equilibrium strategy, how would P2’s expected value change? 

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
It wouldn't! As long as P1 doesn't modify their equilibrium strategy, then P2 can mix his strategy however he wants and have the same EV. 

:::

:::{.callout-note  appearance="minimal"}
## Bluff:Value Ratio Exercise
Given that P2 has bet after P1 checks and is playing the equilibrium strategy, what is the probability that they are bluffing?

(Note: Including cases where you have an A, so Q bets are bluffs and A bets are value bets.)

:::

:::{.callout-warning collapse="true" appearance="minimal"}
## Solution
P2 has Q and A each $\frac{1}{2}$ of the time. 

P2 is betting Q $\frac{1}{3}$ of the time (bluffing). 

P2 is betting A always (value betting). 

Therefore for every 3 times you have Q you will bet once and for every 3 times you have A you will bet 3 times. Out of the 4 bets, 1 of them is a bluff. 

$\Pr(\text{P2 Bluff after P1 Check}) = \frac{1}{4}$

:::

Note: If you play an equilibrium strategy, opponents will only get penalized for playing hands **outside** of the set of hands in the mixed strategy equilibrium (also known as the support, or the set of pure strategies that are played with non-zero probability under the mixed strategy). If opponents are not playing equilibrium, though, then they open themselves up to exploitation. 

## End Games 

### Highest Number Up to 100
Everyone chooses a number, maximum 100. The highest unique number chosen wins. 

### Aumann Game 
Everyone gets a paper with a possible solution to a trivia question -- only one is correct. We then go around and everyone says what probability they believe their answer is correct. 

We had 8 people, so with no info, you'd expect your answer to be 12.5%. We ended with very polarized numbers where most were 0 and there was a 5%, 40%, and 80%. The 5% ended up being correct (better than 0)!. 

![](aumann.jpg)